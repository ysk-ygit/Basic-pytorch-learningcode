import numpy as np
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

#step0 - GPU check
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)

#step1 - データの呼び出しと前処理
data_root = './data'

transform = transforms.Compose([
  transforms.ToTensor(),
  transforms.Normalize(0.5, 0.5),
  transforms.Lambda(lambda x : x.view(-1)),                                
])

train_set = datasets.MNIST(
    root = data_root,
    train = True,
    download = True,
    transform = transform
)

test_set = datasets.MNIST(
    root = data_root,
    train = False,
    download = True,
    transform = transform
)
#データの確認
image, label = train_set[0]
print('Image type: ', type(image))
print('Image shape:', image.shape)
image, label = test_set[0]
print(len(test_set))
print('Image type: ', type(image))
print('Image shape:', image.shape)
print('min: ', image.data.min())
print('max: ', image.data.max())
len(train_set)
image, label = train_set[0]
plt.figure(figsize=(2,2))
plt.title(f'{label}')
plt.imshow(image, cmap = 'gray_r')
plt.show()

#step2 - ミニバッチ処理
batch_size = 500

train_loader = DataLoader(
    train_set,
    batch_size=batch_size,
    shuffle = True
)

test_loader = DataLoader(
    test_set,
    batch_size=batch_size,
    shuffle = True
)
len(train_loader)
for image, label in train_loader:
  break

print(image.shape)
print(label.shape)
n_input = 784
n_output = 10
n_hidden = 128

#step3 - モデルクラスの定義
class Net(nn.Module):
  def __init__(self, n_input, n_output, n_hidden):
    super().__init__()
    self.l1 = nn.Linear(n_input, n_hidden)
    self.l2 = nn.Linear(n_hidden, n_output)
    self.relu = nn.ReLU(inplace=True)

  def forward(self, x):
    x1 = self.l1(x)
    x2 = self.relu(x1)
    x3 = self.l2(x2)
    return x3
net = Net(n_input, n_output, n_hidden).to(device)

#step4 - 損失関数の定義
criterion = nn.CrossEntropyLoss()

#step5 - 最適アルゴリズムの設定(確率的勾配降下法)
lr = 0.01
optimizer = optim.SGD(net.parameters(), lr = lr)
history = np.zeros((0,5))
history

#step6 学習
from tqdm.notebook import tqdm
num_epoch = 100

for epoch in range(num_epoch):
  train_acc, train_loss = 0, 0
  val_acc, val_loss = 0, 0
  n_train, n_test = 0, 0

  for inputs, labels in tqdm(train_loader):
    n_train += len(labels)

    inputs = inputs.to(device)
    labels = labels.to(device)

    optimizer.zero_grad()
    outputs = net(inputs)
    loss = criterion(outputs, labels)
    loss.backward()

    optimizer.step()
    predicted = torch.max(outputs, 1)[1]

    train_loss += loss.item()
    train_acc += (predicted == labels).sum().item()

  for inputs_test, labels_test in test_loader:
    n_test += len(labels_test)

    inputs_test =inputs_test.to(device)
    labels_test = labels_test.to(device)

    outputs_test = net(inputs_test)

    loss_test = criterion(outputs_test, labels_test)

    predicted_test = torch.max(outputs_test, 1)[1]

    val_loss += loss_test.item()
    val_acc += (predicted_test == labels_test).sum().item()

  train_acc = train_acc / n_train
  val_acc = val_acc / n_test
  train_loss = train_loss * batch_size / n_train
  val_loss = val_loss * batch_size / n_test

  print(f'Epoch [{epoch+1}/{num_epoch}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')
  items = np.array([epoch+1, train_loss, train_acc, val_loss, val_acc])
  history = np.vstack((history, items))
  
  #損失と精度の確認

print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )
print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )

#step7 学習曲線の表示

# (1) 学習曲線の表示 (損失)

plt.rcParams['figure.figsize'] = (8,6)
plt.plot(history[:,0], history[:,1], 'b', label='train')
plt.plot(history[:,0], history[:,3], 'k', label='test')
plt.xlabel('iter')
plt.ylabel('loss')
plt.title('loss carve')
plt.legend()
plt.show()

# (2) 学習曲線の表示 (精度)

plt.rcParams['figure.figsize'] = (8,6)
plt.plot(history[:,0], history[:,2], 'b', label='train')
plt.plot(history[:,0], history[:,4], 'k', label='test')
plt.xlabel('iter')
plt.ylabel('acc')
plt.title('accuracy')
plt.legend()
plt.show()





